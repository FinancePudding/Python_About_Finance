{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 从ModelScope下载模型到本地",
   "id": "d2c427878dd8729a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "这里推荐创建一个conda环境，方便使用pycharm进行解释器的配置。",
   "id": "897e19cb8af3ae30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!conda create -n qwen python=3.11 # 推荐使用3.11版本的python，3.12版本的尝试过不兼容，transformers库版本不兼容等问题\n",
    "!conda activate qwen # 激活环境"
   ],
   "id": "e5ef758d2c053779"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh # 安装rust环境\n",
    "!source \"$HOME/.cargo/env.fish\"\n",
    "!rustc --version\n",
    "!reboot"
   ],
   "id": "f640ff1a0b5f4a9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install modelscope transformers==4.32.0 accelerate tiktoken einops scipy transformers_stream_generator==0.0.4 peft deepspeed",
   "id": "cc1d27418745b12f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0572c76b-9f1c-4e70-9b1d-13c1e498bab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 15:09:10,989 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 54.3k/54.3k [00:00<00:00, 821kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 15.0k/15.0k [00:00<00:00, 430kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 237k/237k [00:00<00:00, 1.62MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████| 116k/116k [00:00<00:00, 962kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 2.44M/2.44M [00:00<00:00, 6.64MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 473k/473k [00:00<00:00, 2.45MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 14.3k/14.3k [00:00<00:00, 361kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 79.0k/79.0k [00:00<00:00, 1.09MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 46.4k/46.4k [00:00<00:00, 557kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 0.98M/0.98M [00:00<00:00, 4.00MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 205k/205k [00:00<00:00, 1.74MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 19.4k/19.4k [00:00<00:00, 521kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 302k/302k [00:00<00:00, 2.15MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 615k/615k [00:00<00:00, 3.05MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 376k/376k [00:00<00:00, 1.81MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 445k/445k [00:00<00:00, 2.12MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 25.9k/25.9k [00:00<00:00, 663kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 395k/395k [00:00<00:00, 2.33MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 176k/176k [00:00<00:00, 1.46MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 182k/182k [00:00<00:00, 1.45MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 824k/824k [00:00<00:00, 3.63MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 426k/426k [00:00<00:00, 2.79MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 433k/433k [00:00<00:00, 2.73MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 2.34MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 403k/403k [00:00<00:00, 2.20MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 9.39k/9.39k [00:00<00:00, 23.5MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 403k/403k [00:00<00:00, 2.32MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 79.0k/79.0k [00:00<00:00, 1.06MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████| 173/173 [00:00<00:00, 402kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 41.9k/41.9k [00:00<00:00, 558kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 230k/230k [00:00<00:00, 1.48MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 1.27M/1.27M [00:00<00:00, 4.84MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 664k/664k [00:00<00:00, 3.00MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 404k/404k [00:00<00:00, 1.96MB/s]\n",
      "2024-05-13 15:09:26,781 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████▉| 1.90G/1.90G [03:09<00:00, 10.7MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████▉| 1.52G/1.52G [02:41<00:00, 10.1MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 14.4k/14.4k [00:00<00:00, 432kB/s]\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba252b14f74948aaaa1d5dbc1de98212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 15:15:33,897 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_dir = snapshot_download('qwen/Qwen-1_8B-Chat')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_dir, \n",
    "    trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d7ad2-c388-4eb1-8284-b0a5398ccc19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c8b5e8-23dc-40e6-a921-7e024d3e0d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/modelscope/hub/qwen/Qwen-1_8B-Chat\n"
     ]
    }
   ],
   "source": "print(model_dir) # 模型目录"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!mv /root/.cache/modelscope/hub/qwen /root/QwenLLM/qwen # 移动模型到指定目录",
   "id": "dbec107f1266aa9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 模型运行测试",
   "id": "caca7cf7662cc728"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "from modelscope import GenerationConfig\n",
    "\n",
    "model_dir = '/root/QwenLLM/qwen/Qwen-1_8B-Chat'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_dir, trust_remote_code=True) # 可指定不同的生成长度、top_p等相关超参"
   ],
   "id": "1060249b26214663"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response, history = model.chat(tokenizer, \"你好\", system='使用秦始皇的语气和我说话，要显示出始皇帝的威严', history=None)\n",
    "print(response)"
   ],
   "id": "22c258b6f91cb1ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response, history = model.chat(tokenizer, \"陛下为什么能够统一六国？\", system='使用秦始皇的语气和我说话，要显示出始皇帝的威严', history=history)\n",
    "print(response)"
   ],
   "id": "c1376d06029c9e89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "323d6beb970793a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
